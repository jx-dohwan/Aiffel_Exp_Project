{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Exp_11]Creating a CIFAR-10 Image.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyN181kdo2qlnLXKUG24054I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jx-dohwan/Aiffel_EGLMS_Project/blob/main/%5BExp_11%5DCreating_a_CIFAR_10_Image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. import 및 데이터 로드"
      ],
      "metadata": {
        "id": "zSgLWj1bcM0V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번에는 앞에서 배운 FASHION-MNIST 데이터 생성용 DCGAN 모델구조를 이용해서 CIFAR-10 데이터를 생성하는 모델을 직접 만들어 봅시다.\n",
        "모델 구현 및 학습의 전과정의 흐름은 거의 비슷하겠지만, 아래와 같이 몇 가지 달라지는 점이 있습니다.\n",
        "\n",
        "- 이미지 데이터의 shape가 (28, 28, 1)에서 (32, 32, 3)으로 변경됩니다. 생성자, 판별자 모델의 입출력 shape 및 모델 구조에 영향이 있습니다.\n",
        "- 이미지가 단색의 grayscale에서 RGB 3채널의 컬러이미지로 변경됩니다. 시각화 과정에서 고려할 점이 있습니다.\n",
        "- 입력데이터 전체 차원이 3~4배 증가하면서, 학습이 진행되는 양상이 다소 달라집니다."
      ],
      "metadata": {
        "id": "c1kJJMMeb2E_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import imageio"
      ],
      "metadata": {
        "id": "0Ttk_v6daMPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xz_L9isJX80Z",
        "outputId": "d0771889-3102-47a0-d265-3a93af4a53dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n",
            "170508288/170498071 [==============================] - 11s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "cifar10 = tf.keras.datasets.cifar10\n",
        "\n",
        "(train_x, _), (test_x, _) = cifar10.load_data()\n",
        "\n",
        "train_x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 데이터셋 구성하기\n",
        "- 학습에 사용할 train_x의 이미지를 -1, 1로 정규화합니다.\n",
        "- 로드한 학습 데이터를 시각화를 통해 확인해 봅시다.\n",
        "- tf.data.Dataset 모듈의 from_tensor_slices() 함수를 사용하여 미니배치 데이터셋을 구성해 봅시다."
      ],
      "metadata": {
        "id": "FUFYtEG7cSh-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 생성자 모델 구현하기\n",
        "- (32, 32, 3)의 shape를 가진 이미지를 생성하는 생성자 모델 구현 함수를 작성해 봅시다.\n",
        "- noise = tf.random.normal([1, 100])로 생성된 랜덤 노이즈를 입력으로 하여 방금 구현한 생성자로 랜덤 이미지를 생성해 봅시다.\n",
        "- 생성된 랜덤 이미지가 생성자 출력 규격에 잘 맞는지 확인해 봅시다."
      ],
      "metadata": {
        "id": "gwJy50hHcWzK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 판별자 모델 구현하기\n",
        "- (32, 32, 3)의 이미지를 입력으로 받아 1dim을 판별결과를 출력하는 판별자 모델 구현 함수를 작성해 봅시다.\n",
        "- 위 STEP 2에서 생성한 랜덤 이미지를 판별자 모델이 판별한 결과값을 확인해 봅시다."
      ],
      "metadata": {
        "id": "ZfqUrGB1cZpz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 손실함수와 최적화 함수 구현하기\n",
        "- 생성자와 판별자의 손실함수(loss)를 구현해 봅시다.\n",
        "- 판별자의 출력값을 가지고 실제/생성(real/fake) 이미지 판별 정확도(accuracy)를 계산하는 함수를 구현해 봅시다.\n",
        "- 생성자와 판별자를 최적화하는 optimizer를 정의합니다."
      ],
      "metadata": {
        "id": "MExn0gpCcZou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. 훈련과정 상세 기능 구현하기\n",
        "- 1개 미니배치의 훈련 과정을 처리하는 train_step() 함수를 구현해 봅시다.\n",
        "- 16개의 고정된 seed를 입력으로 하여 훈련 과정 동안 생성한 이미지를 시각화하는 generate_and_save_images() 함수를 구현해 봅시다.\n",
        "- 훈련 epoch마다 생성자/판별자의 loss 및 판별자의 실제/생성(real/fake) 이미지 판별 accuracy 히스토리(history)를 그래프로 시각화하는 draw_train_history() 함수를 구현해 봅시다.\n",
        "- training_checkpoints 디렉토리에 몇 epoch마다 모델을 저장하는 checkpoint 모듈을 설정해 봅시다."
      ],
      "metadata": {
        "id": "7d2WzOC_chhG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. 학습 과정 진행하기\n",
        "- 위 STEP 5에서 구현한 기능들을 활용하여 최소 50 epoch만큼의 모델 학습을 진행해 봅시다.\n",
        "- 학습 과정에서 생성된 샘플 이미지로 만든 gif 파일을 통해 학습 진행 과정을 시각적으로 표현해 봅시다.\n",
        "- 학습 과정을 담은 샘플 이미지, gif 파일, 학습 진행 그래프 이미지를 함께 제출합니다.\n",
        "> (참고) 학습 과정 중 학습 epoch를 추가 진행해야 하거나, 학습한 모델을 활용하여 이미지를 생성할 필요가 생깁니다. 그럴 때마다 모델 학습을 처음부터 다시 진행한다면 시간 낭비가 될 것입니다.\n",
        "우리는 위에서 checkpoint 모듈을 이용해 모델을 저장해 둔 바 있습니다. 이를 이용해 학습해 둔 모델을 로드하면 모델 재학습이 필요 없이 이런 작업을 진행할 수 있습니다.\n",
        "아래는 checkpoint 모듈을 활용하여 모델을 로드하는 예시입니다."
      ],
      "metadata": {
        "id": "FoLI_ZQLclE8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. (optional) GAN 훈련 과정 개선하기\n",
        "- STEP 6을 진행하면서 생성된 샘플 이미지, 학습 과정 그래프 등을 통해 이전 훈련 과정의 문제점을 분석해 봅시다.\n",
        "- 모델구조 또는 학습 과정을 개선한 내역과 그 결과(샘플 이미지, 학습 과정 그래프 포함)를 함께 제출합니다.\n",
        "> (참고) 아래 언급된 페이지들에서 개선을 위한 아이디어를 얻을 수 있을 것입니다.\n",
        "> - https://github.com/soumith/ganhacks\n",
        "> - https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628\n",
        "> - https://machinelearningmastery.com/how-to-train-stable-generative-adversarial-networks/\n",
        "> - https://proceedings.neurips.cc/paper/2016/file/8a3363abe792db2d8761d6403605aeb7-Paper.pdf"
      ],
      "metadata": {
        "id": "PNjHaXAycofZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MrHt8hd3aHiU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}